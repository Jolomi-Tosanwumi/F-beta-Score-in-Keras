{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiLabel.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPALfhPa9l/11Ul8xAwToFo"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQQGh0z-bk5C"
      },
      "source": [
        "# importing useful libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "# setting random seed for result reproducibility\n",
        "np.random.seed(1)\n",
        "python_random.seed(12)\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Metric\n",
        "\n",
        "from sklearn.datasets import make_multilabel_classification\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p5865ursyjQ"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF4RjUB-Bh-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b568113a-a2e4-4459-fd7c-bc28485c7441"
      },
      "source": [
        "X, y = make_multilabel_classification(n_samples=60000, n_features=5000, n_classes=20, n_labels=4, length=100, allow_unlabeled=False, sparse=False, return_indicator='dense', return_distributions=False, random_state=1)\n",
        "print('shape of X is {}'.format(X.shape))\n",
        "print('shape of y is {}'.format(y.shape))\n",
        "\n",
        "tfidf = TfidfTransformer() # initializes a TfidfTransformer\n",
        "Xt = tfidf.fit_transform(X) # fits and transforms X"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X is (60000, 5000)\n",
            "shape of y is (60000, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgpq_mwjEtia"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHktn-XcHywK"
      },
      "source": [
        "beta = 2 # arbitrarily setting beta to 2. You can set it to any value you choose to\n",
        "threshold = 0.2 # arbitrarily setting beta to 0.2. You can set it to any value you choose to\n",
        "\n",
        "def multi_label_fbeta(ytrue , ypred, beta=beta, average='samples', threshold=threshold, epsilon=1e-7, \\\n",
        "                      sample_weight=None):\n",
        "    # epsilon is set to avoid division by zero error\n",
        "    beta_squared = beta**2\n",
        "\n",
        "    # casting ytrue and ypred as floats\n",
        "    ytrue = tf.cast(ytrue, tf.float32)\n",
        "    \n",
        "    # making ypred one hot encoded \n",
        "    ypred = tf.cast(tf.greater_equal(tf.cast(ypred, tf.float32), tf.constant(threshold)), tf.float32)\n",
        "    \n",
        "    if average == 'samples':\n",
        "        tp = tf.reduce_sum(ytrue * ypred, axis=-1) # calculating true positives\n",
        "        predicted_positive = tf.reduce_sum(ypred, axis=-1) # calculating predicted positives\n",
        "        actual_positive = tf.reduce_sum(ytrue, axis=-1) # calculating actual positives\n",
        "    \n",
        "    else: # either any of 'macro', 'weighted' and 'raw'\n",
        "        tp = tf.reduce_sum(ytrue * ypred, axis=0) # calculating true positives\n",
        "        predicted_positive = tf.reduce_sum(ypred, axis=0) # calculating predicted positives\n",
        "        actual_positive = tf.reduce_sum(ytrue, axis=0) # calculating actual positives\n",
        "    \n",
        "    # calculating precision and recall\n",
        "    precision = tp/(predicted_positive+epsilon)\n",
        "    recall = tp/(actual_positive+epsilon)\n",
        "\n",
        "    # finding fbeta\n",
        "    fb = (1+beta_squared)*precision*recall / (beta_squared*precision + recall + epsilon)\n",
        "\n",
        "    if average == 'weighted':\n",
        "        supports = tf.reduce_sum(ytrue, axis=0)\n",
        "        return tf.reduce_sum(fb*supports / tf.reduce_sum(supports))\n",
        "\n",
        "    elif average == 'raw':\n",
        "        return fb\n",
        "    \n",
        "    elif average == 'samples' and sample_weight is not None:\n",
        "        return tf.reduce_sum(fb*sample_weight)\n",
        "    \n",
        "    return tf.reduce_mean(fb) # then it is either 'macro' or 'samples' (without sample weight)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KIK0vt2IaOX"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckGfid_EEwzm"
      },
      "source": [
        "def build_model(start=512, metrics=multi_label_fbeta, run_eagerly=False, lr=1e-3):\n",
        "    model = Sequential() # initializes a sequential model\n",
        "\n",
        "    # adding three layers where a filter size is half of the preceding filter size\n",
        "    for _ in range(3):\n",
        "      model.add(Dense(start, activation='relu'))\n",
        "      start //= 2\n",
        "\n",
        "    #model.add(Flatten()) # flattens the layer\n",
        "\n",
        "    model.add(Dense(20, activation='sigmoid')) # ouput layer\n",
        "\n",
        "    opt = Adam(lr=lr) # initializes an optimizer\n",
        "\n",
        "    # compling model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[metrics], run_eagerly=run_eagerly)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rdzc1AWE89Q"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea7poqvCIBAo",
        "outputId": "6a1de1f3-68cc-4221-84c0-a9084d894200"
      },
      "source": [
        "model = build_model()\n",
        "model.fit(X, y, batch_size=128, epochs=3, validation_split=0.2, shuffle=False);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4072 - multi_label_fbeta: 0.6116 - val_loss: 0.3709 - val_multi_label_fbeta: 0.6588\n",
            "Epoch 2/3\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3180 - multi_label_fbeta: 0.7253 - val_loss: 0.3759 - val_multi_label_fbeta: 0.6672\n",
            "Epoch 3/3\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2358 - multi_label_fbeta: 0.8139 - val_loss: 0.4409 - val_multi_label_fbeta: 0.6368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlzEPZAWtQDJ"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY4ofMc6mYuF",
        "outputId": "5859f1d4-c343-4245-e2a9-d25b3ba3d231"
      },
      "source": [
        "random_ytrue = np.random.choice([0, 1], (20, 17))\n",
        "random_ypred = np.random.choice([0, 1], (20, 17))\n",
        "\n",
        "print('f1_score of prediction using multi_label_fbeta is {}'.format(multi_label_fbeta(random_ytrue, random_ypred)))\n",
        "print('f1_score of prediction using scikit-learn fbeta is {}'.format(fbeta_score(\\\n",
        "                                                    random_ytrue, random_ypred, beta=2, average='samples')))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score of prediction using multi_label_fbeta is 0.46118515729904175\n",
            "f1_score of prediction using scikit-learn fbeta is 0.4611851797939628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsKY92xzIA-F"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDIOyoKGIA51"
      },
      "source": [
        "n_class = 20\n",
        "\n",
        "class StatefullMultiLabelFBeta(Metric):\n",
        "    def __init__(self, name='state_full_binary_fbeta', beta=beta, average='samples', \\\n",
        "                 n_class=n_class, threshold=threshold, epsilon=1e-7, **kwargs):\n",
        "        \n",
        "        # initializing an object of the super class\n",
        "        super(StatefullMultiLabelFBeta, self).__init__(name=name, **kwargs)\n",
        "            \n",
        "        # initializing atrributes\n",
        "        self.tp = self.add_weight(name='tp', shape=(n_class,), initializer='zeros') # initializing true positives\n",
        "        self.actual_positives = self.add_weight(name='ap', shape=(n_class,), initializer='zeros') \n",
        "        self.predicted_positives = self.add_weight(name='pp', shape=(n_class,), initializer='zeros')\n",
        "\n",
        "        self.n_samples = self.add_weight(name='n_samples', initializer='zeros')\n",
        "        self.sum_fb = self.add_weight(name='sum_fb', initializer='zeros')\n",
        "\n",
        "        # initializing other atrributes that wouldn't be changed for every object of this class\n",
        "        self.beta_squared = beta**2\n",
        "        self.average = average\n",
        "        self.n_class = n_class\n",
        "        self.threshold = threshold\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def update_state(self, ytrue, ypred, sample_weight=None):\n",
        "        # casting ytrue float dtype\n",
        "        ytrue = tf.cast(ytrue, tf.float32)\n",
        "        \n",
        "        # making ypred one hot encoded \n",
        "        ypred = tf.cast(tf.greater_equal(tf.cast(ypred, tf.float32), tf.constant(threshold)), tf.float32)\n",
        "        \n",
        "        if self.average == 'samples': # we are to keep track of only fbeta\n",
        "            # calculate true positives, predicted positives and actual positives atrribute along the last axis\n",
        "            tp = tf.reduce_sum(ytrue*ypred, axis=-1) \n",
        "            predicted_positives = tf.reduce_sum(ypred, axis=-1)\n",
        "            actual_positives = tf.reduce_sum(ytrue, axis=-1)\n",
        "            \n",
        "            precision = tp/(predicted_positives+self.epsilon) # calculate the precision\n",
        "            recall = tp/(actual_positives+self.epsilon) # calculate the recall\n",
        "            \n",
        "            # calculate the fbeta score\n",
        "            fb = (1+self.beta_squared)*precision*recall / (self.beta_squared*precision + \\\n",
        "                                                                      recall + self.epsilon)\n",
        "            \n",
        "            if sample_weight is not None: # if sample weight is available for stand alone usage\n",
        "                self.fb = tf.reduce_sum(fb*sample_weight)\n",
        "            else:\n",
        "                n_rows = tf.reduce_sum(tf.shape(ytrue)*tf.constant([1, 0])) # getting the number of rows in ytrue\n",
        "                self.n_samples.assign_add(tf.cast(n_rows, tf.float32)) # updating n_samples\n",
        "                self.sum_fb.assign_add(tf.reduce_sum(fb)) # getting the running sum of fb\n",
        "                self.fb = self.sum_fb / self.n_samples # getting the running mean of fb\n",
        "\n",
        "        else:\n",
        "            # keep track of true, predicted and actual positives because they are calculated along axis 0\n",
        "            self.tp.assign_add(tf.reduce_sum(ytrue*ypred, axis=0)) \n",
        "            self.assign_add(predicted_positives = tf.reduce_sum(ypred, axis=0))\n",
        "            self.actual_positives.assign_add(tf.reduce_sum(ytrue, axis=0)) \n",
        "            \n",
        "    def result(self):\n",
        "        if self.average != 'samples':\n",
        "            precision = self.tp/(self.predicted_positives+self.epsilon) # calculate the precision\n",
        "            recall = self.tp/(self.actual_positives+self.epsilon) # calculate the recall\n",
        "\n",
        "            # calculate the fbeta score\n",
        "            fb = (1+self.beta_squared)*precision*recall / (self.beta_squared*precision + \\\n",
        "                                                                      recall + self.epsilon)\n",
        "            if self.average == 'weighted':\n",
        "                return tf.reduce_sum(fb*self.actual_positives / tf.reduce_sum(self.actual_positives))\n",
        "\n",
        "            elif self.average == 'raw':\n",
        "                return fb\n",
        "            \n",
        "            return tf.reduce_mean(fb) # then it is 'macro' averaging \n",
        "    \n",
        "        return self.fb # then it is either 'samples' with or without sample weight\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.tp.assign(tf.zeros(self.n_class)) # resets true positives to zero\n",
        "        self.predicted_positives.assign(tf.zeros(self.n_class)) # resets predicted positives to zero\n",
        "        self.actual_positives.assign(tf.zeros(self.n_class)) # resets actual positives to zero\n",
        "        self.n_samples.assign(0)\n",
        "        self.sum_fb.assign(0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfBQ6yY5lKqx"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FROQyjghlKd7",
        "outputId": "fc7dea45-feee-4297-9f0d-bd455b58a244"
      },
      "source": [
        "stateful_multi_label_fbeta = StatefullMultiLabelFBeta()\n",
        "stateful_model = build_model(metrics=stateful_multi_label_fbeta)\n",
        "stateful_model.fit(X, y, batch_size=128, epochs=3, validation_split=0.2, shuffle=False);"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4108 - state_full_binary_fbeta: 0.6071 - val_loss: 0.3712 - val_state_full_binary_fbeta: 0.6604\n",
            "Epoch 2/3\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3223 - state_full_binary_fbeta: 0.7212 - val_loss: 0.3729 - val_state_full_binary_fbeta: 0.6701\n",
            "Epoch 3/3\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2445 - state_full_binary_fbeta: 0.8070 - val_loss: 0.4273 - val_state_full_binary_fbeta: 0.6494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_djEbnVnwC06"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeFWQ09amBJ3",
        "outputId": "75bdb6a8-ee4d-4fdb-f5d0-d020a081823f"
      },
      "source": [
        "n_sample = 100\n",
        "n_class = 20\n",
        "m = StatefullMultiLabelFBeta(n_class=n_class) # initializes a stateful multi class fbeta object\n",
        "\n",
        "random_ytrue = np.random.choice([0, 1], (n_sample, n_class))\n",
        "random_ypred = np.random.choice([0, 1], (n_sample, n_class))\n",
        "\n",
        "m.update_state(random_ytrue, random_ypred)\n",
        "print('Intermediate result for stateful multi class fbeta is: {}'.format(float(m.result())))\n",
        "print('Intermediate result for scikit-learn fbeta is: {}'.format(fbeta_score(\\\n",
        "                                                        random_ytrue, random_ypred, beta=2, average='samples')))\n",
        "print()\n",
        "\n",
        "increment_size = 20\n",
        "a_true = np.random.choice([0, 1], (increment_size, n_class))\n",
        "a_pred = np.random.choice([0, 1], (increment_size, n_class))\n",
        "\n",
        "m.update_state(a_true, a_pred)\n",
        "print('Final result for stateful multi class fbeta is: {}'.format(float(m.result())))\n",
        "\n",
        "arr_true = np.append(random_ytrue, a_true, axis=0)\n",
        "arr_pred = np.append(random_ypred, a_pred, axis=0)\n",
        "\n",
        "print('Final result for scikit-learn multi class fbeta is: {}'.format(\\\n",
        "                                                    fbeta_score(arr_true, arr_pred, beta=2, average='samples')))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intermediate result for stateful multi class fbeta is: 0.49903061985969543\n",
            "Intermediate result for scikit-learn fbeta is: 0.49903061948857347\n",
            "\n",
            "Final result for stateful multi class fbeta is: 0.5037157535552979\n",
            "Final result for scikit-learn multi class fbeta is: 0.503715777491389\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}